import torch
import torch.nn as nn
import torchvision
import torchvision.transforms as transforms
from torch.utils.data import DataLoader
import matplotlib.pyplot as plt
from torch.optim.lr_scheduler import StepLR
from linear_layer import LinearL

# Define model, optimizer, scheduler, and criterion
layers_hidden = [28 * 28, 128, 64, 10]
model = LinearL(layers_hidden)
optimizer = torch.optim.AdamW(model.parameters(), lr=1e-4, weight_decay=1e-4)
scheduler = StepLR(optimizer, step_size=5, gamma=0.7)
criterion = nn.CrossEntropyLoss()
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

# Load MNIST with enhanced data augmentation
transform = transforms.Compose(
    [
        transforms.RandomRotation(10),  # Random rotation
        transforms.RandomAffine(0, shear=10, scale=(0.8, 1.2)),  # Random affine transformations
        transforms.ToTensor(),
        transforms.Normalize((0.5,), (0.5,))
    ]
)
trainset = torchvision.datasets.MNIST(
    root="./data", train=True, download=True, transform=transform
)
valset = torchvision.datasets.MNIST(
    root="./data", train=False, download=True, transform=transform
)
trainloader = DataLoader(trainset, batch_size=64, shuffle=True)
valloader = DataLoader(valset, batch_size=64, shuffle=False)

# Train the model
model.train_model(model, trainloader, valloader, optimizer, scheduler, criterion, device, epochs=30)

# Test the model for a few values
num_samples_to_test = 10
predictions, ground_truths, images_to_show = model.test_model(model, valloader, device, num_samples=num_samples_to_test)

# Optionally visualize the test samples and their predictions
fig, axes = plt.subplots(1, num_samples_to_test, figsize=(15, 2))
for i in range(num_samples_to_test):
    axes[i].imshow(images_to_show[i], cmap='gray')
    axes[i].set_title(f'Pred: {predictions[i]}, GT: {ground_truths[i]}')
    axes[i].axis('off')
plt.show()
